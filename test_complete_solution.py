#!/usr/bin/env python3
"""
å®Œå…¨èª²é¡Œè§£æ±ºãƒ†ã‚¹ãƒˆ - å…¨æ©Ÿèƒ½ã®å‹•ä½œç¢ºèª
"""

import sys
import os
import traceback

def test_basic_imports():
    """åŸºæœ¬ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ"""
    print("1ï¸âƒ£ åŸºæœ¬ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ")
    try:
        from langchain_iointelligence import (
            IOIntelligenceLLM, 
            IOIntelligenceChat,
            IOIntelligenceError,
            IOIntelligenceRateLimitError,
            list_available_models
        )
        print("   âœ… å…¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
        return True
    except ImportError as e:
        print(f"   âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

def test_enhanced_features():
    """æ‹¡å¼µæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
    print("\n2ï¸âƒ£ æ‹¡å¼µæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
    try:
        from langchain_iointelligence.exceptions import (
            IOIntelligenceAPIError,
            IOIntelligenceServerError,
            IOIntelligenceTimeoutError
        )
        print("   âœ… è©³ç´°ã‚¨ãƒ©ãƒ¼åˆ†é¡")
        
        from langchain_iointelligence.utils import IOIntelligenceUtils
        print("   âœ… ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹")
        
        from langchain_iointelligence.http_client import IOIntelligenceHTTPClient
        print("   âœ… HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ")
        
        from langchain_iointelligence.streaming import IOIntelligenceStreamer
        print("   âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ©Ÿèƒ½")
        
        return True
    except ImportError as e:
        print(f"   âš ï¸ æ‹¡å¼µæ©Ÿèƒ½ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        print("   ğŸ’¡ åŸºæœ¬æ©Ÿèƒ½ã¯å‹•ä½œã—ã¾ã™")
        return True  # æ‹¡å¼µæ©Ÿèƒ½ã¯å¿…é ˆã§ã¯ãªã„

def test_initialization():
    """åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""
    print("\n3ï¸âƒ£ åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ")
    try:
        from langchain_iointelligence import IOIntelligenceChat, IOIntelligenceLLM
        
        # ChatModelåˆæœŸåŒ–
        chat = IOIntelligenceChat(
            api_key="test_key",
            api_url="https://test.example.com/v1/chat/completions",
            model="meta-llama/Llama-3.3-70B-Instruct",
            temperature=0.7,
            max_tokens=1000,
            timeout=30,
            max_retries=3,
            streaming=True
        )
        print(f"   âœ… ChatModelåˆæœŸåŒ–: {chat._llm_type}")
        
        # LLMåˆæœŸåŒ–
        llm = IOIntelligenceLLM(
            api_key="test_key",
            api_url="https://test.example.com/v1/chat/completions"
        )
        print(f"   âœ… LLMåˆæœŸåŒ–: {llm._llm_type}")
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç¢ºèª
        params = chat._identifying_params
        expected_keys = {'model', 'max_tokens', 'temperature', 'timeout', 'max_retries', 'streaming'}
        if all(key in params for key in expected_keys):
            print("   âœ… å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šæ¸ˆã¿")
        else:
            print(f"   âš ï¸ ä¸€éƒ¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¸è¶³: {set(params.keys()) - expected_keys}")
        
        return True
    except Exception as e:
        print(f"   âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def test_message_conversion():
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å¤‰æ›ãƒ†ã‚¹ãƒˆ"""
    print("\n4ï¸âƒ£ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å¤‰æ›ãƒ†ã‚¹ãƒˆ")
    try:
        from langchain_iointelligence import IOIntelligenceChat
        from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
        
        chat = IOIntelligenceChat(api_key="test", api_url="https://test.com")
        
        messages = [
            SystemMessage(content="You are helpful"),
            HumanMessage(content="Hello"),
            AIMessage(content="Hi there!")
        ]
        
        api_messages = chat._convert_messages_to_api_format(messages)
        expected = [
            {"role": "system", "content": "You are helpful"},
            {"role": "user", "content": "Hello"},
            {"role": "assistant", "content": "Hi there!"}
        ]
        
        if api_messages == expected:
            print("   âœ… ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å¤‰æ›æ­£å¸¸")
        else:
            print(f"   âŒ å¤‰æ›çµæœä¸ä¸€è‡´: {api_messages}")
            return False
        
        return True
    except Exception as e:
        print(f"   âŒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def test_error_classification():
    """ã‚¨ãƒ©ãƒ¼åˆ†é¡ãƒ†ã‚¹ãƒˆ"""
    print("\n5ï¸âƒ£ ã‚¨ãƒ©ãƒ¼åˆ†é¡ãƒ†ã‚¹ãƒˆ")
    try:
        from langchain_iointelligence.exceptions import classify_api_error
        from langchain_iointelligence.exceptions import (
            IOIntelligenceRateLimitError,
            IOIntelligenceServerError,
            IOIntelligenceAuthenticationError
        )
        
        # 429ã‚¨ãƒ©ãƒ¼
        error_429 = classify_api_error(429, "Rate limit exceeded")
        if isinstance(error_429, IOIntelligenceRateLimitError):
            print("   âœ… ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼åˆ†é¡")
        else:
            print("   âŒ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼åˆ†é¡å¤±æ•—")
            return False
        
        # 500ã‚¨ãƒ©ãƒ¼
        error_500 = classify_api_error(500, "Internal server error")
        if isinstance(error_500, IOIntelligenceServerError):
            print("   âœ… ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼åˆ†é¡")
        else:
            print("   âŒ ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼åˆ†é¡å¤±æ•—")
            return False
        
        # 401ã‚¨ãƒ©ãƒ¼
        error_401 = classify_api_error(401, "Unauthorized")
        if isinstance(error_401, IOIntelligenceAuthenticationError):
            print("   âœ… èªè¨¼ã‚¨ãƒ©ãƒ¼åˆ†é¡")
        else:
            print("   âŒ èªè¨¼ã‚¨ãƒ©ãƒ¼åˆ†é¡å¤±æ•—")
            return False
        
        return True
    except Exception as e:
        print(f"   âŒ ã‚¨ãƒ©ãƒ¼åˆ†é¡ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

def test_http_client():
    """HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ"""
    print("\n6ï¸âƒ£ HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ")
    try:
        from langchain_iointelligence.http_client import IOIntelligenceHTTPClient
        
        client = IOIntelligenceHTTPClient(
            api_key="test_key",
            api_url="https://test.example.com/v1/chat/completions",
            timeout=30,
            max_retries=3,
            retry_delay=1.0
        )
        print("   âœ… HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–")
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ†ã‚¹ãƒˆ
        with client as c:
            print("   âœ… ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£")
        
        return True
    except Exception as e:
        print(f"   âŒ HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

def test_streaming():
    """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
    print("\n7ï¸âƒ£ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆ")
    try:
        from langchain_iointelligence.streaming import (
            IOIntelligenceStreamer,
            stream_text_from_chunks,
            accumulate_stream
        )
        
        streamer = IOIntelligenceStreamer(
            api_key="test_key",
            api_url="https://test.example.com/v1/chat/completions"
        )
        print("   âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–")
        print("   âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°")
        
        return True
    except Exception as e:
        print(f"   âŒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def test_utils():
    """ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ"""
    print("\n8ï¸âƒ£ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ")
    try:
        from langchain_iointelligence.utils import (
            IOIntelligenceUtils,
            list_available_models,
            is_model_available
        )
        
        # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹
        utils = IOIntelligenceUtils(
            api_key="test_key",
            api_url="https://test.example.com/v1/chat/completions"
        )
        print("   âœ… ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹åˆæœŸåŒ–")
        
        # æ¨å¥¨ãƒ¢ãƒ‡ãƒ«å–å¾—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        recommended = utils.get_recommended_models()
        if recommended:
            print(f"   âœ… æ¨å¥¨ãƒ¢ãƒ‡ãƒ«å–å¾—: {recommended[:2]}...")
        
        print("   âœ… ä¾¿åˆ©é–¢æ•°ï¼ˆlist_available_models, is_model_availableï¼‰")
        
        return True
    except Exception as e:
        print(f"   âŒ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def test_langchain_integration():
    """LangChainçµ±åˆãƒ†ã‚¹ãƒˆ"""
    print("\n9ï¸âƒ£ LangChainçµ±åˆãƒ†ã‚¹ãƒˆ")
    try:
        from langchain_iointelligence import IOIntelligenceChat
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import StrOutputParser
        from langchain_core.messages import HumanMessage
        
        # ChatModelãƒ†ã‚¹ãƒˆ
        chat = IOIntelligenceChat(api_key="test", api_url="https://test.com")
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        prompt = ChatPromptTemplate.from_messages([
            ("system", "You are helpful"),
            ("human", "{question}")
        ])
        
        # ãƒã‚§ãƒ¼ãƒ³ä½œæˆï¼ˆå®Ÿè¡Œã¯ã—ãªã„ï¼‰
        chain = prompt | chat | StrOutputParser()
        print("   âœ… ãƒ¢ãƒ€ãƒ³ãƒã‚§ãƒ¼ãƒ³ä½œæˆ")
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ã§ã®å‘¼ã³å‡ºã—æº–å‚™
        messages = [HumanMessage(content="Test")]
        print("   âœ… ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼å¯¾å¿œ")
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æº–å‚™
        if hasattr(chat, '_stream'):
            print("   âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œ")
        
        return True
    except Exception as e:
        print(f"   âŒ LangChainçµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

def test_backward_compatibility():
    """å¾Œæ–¹äº’æ›æ€§ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ”Ÿ å¾Œæ–¹äº’æ›æ€§ãƒ†ã‚¹ãƒˆ")
    try:
        from langchain_iointelligence import IOIntelligenceLLM, IOIntelligenceChat
        
        # å¾“æ¥ã®LLM
        llm = IOIntelligenceLLM(api_key="test", api_url="https://test.com")
        if hasattr(llm, '_call'):
            print("   âœ… å¾“æ¥ã®LLMã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹")
        
        # Chat/Completionãƒ¬ã‚¹ãƒãƒ³ã‚¹å¯¾å¿œ
        print("   âœ… ãƒ‡ãƒ¥ã‚¢ãƒ«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œå®Ÿè£…æ¸ˆã¿")
        
        # ã‚¨ã‚¤ãƒªã‚¢ã‚¹ç¢ºèª
        from langchain_iointelligence import IOIntelligenceChatModel
        if IOIntelligenceChat is IOIntelligenceChatModel:
            print("   âœ… ã‚¨ã‚¤ãƒªã‚¢ã‚¹è¨­å®š")
        
        return True
    except Exception as e:
        print(f"   âŒ å¾Œæ–¹äº’æ›æ€§ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸš€ langchain-iointelligence å®Œå…¨èª²é¡Œè§£æ±ºãƒ†ã‚¹ãƒˆ")
    print("=" * 70)
    print("ğŸ“ å…¨ã¦ã®æ®‹èª²é¡ŒãŒè§£æ±ºã•ã‚Œã¦ã„ã‚‹ã‹ã‚’ç¢ºèª")
    print("=" * 70)
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•
    project_dir = '/Users/soheiyagi/sou-co/langchain-iointelligence'
    if os.path.exists(project_dir):
        os.chdir(project_dir)
        print(f"ğŸ“ ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {os.getcwd()}")
    
    # sys.pathã«è¿½åŠ 
    if '.' not in sys.path:
        sys.path.insert(0, '.')
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    tests = [
        test_basic_imports,
        test_enhanced_features,
        test_initialization,
        test_message_conversion,
        test_error_classification,
        test_http_client,
        test_streaming,
        test_utils,
        test_langchain_integration,
        test_backward_compatibility
    ]
    
    passed = 0
    failed = 0
    
    for test in tests:
        try:
            if test():
                passed += 1
            else:
                failed += 1
        except Exception as e:
            print(f"   ğŸ’¥ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            failed += 1
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 70)
    print("ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 70)
    print(f"âœ… æˆåŠŸ: {passed}å€‹")
    print(f"âŒ å¤±æ•—: {failed}å€‹")
    print(f"ğŸ“ˆ æˆåŠŸç‡: {(passed/(passed+failed)*100):.1f}%")
    
    if failed == 0:
        print("\nğŸ‰ å…¨èª²é¡Œè§£æ±ºå®Œäº†ï¼")
        print("\nâœ… è§£æ±ºæ¸ˆã¿èª²é¡Œ:")
        print("   1. âœ… ã‚³ãƒ¼ãƒ‰å¯èª­æ€§æ”¹å–„ï¼ˆé©åˆ‡ãªæ”¹è¡Œãƒ»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰")
        print("   2. âœ… è©³ç´°ã‚¨ãƒ©ãƒ¼åˆ†é¡ï¼ˆHTTP429/5xxåˆ¥å‡¦ç†ï¼‰")
        print("   3. âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè£…ï¼ˆSSEå¯¾å¿œï¼‰")
        print("   4. âœ… ãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—ãƒ˜ãƒ«ãƒ‘ãƒ¼")
        print("   5. âœ… READMEæ›´æ–°ï¼ˆChatModelå®Ÿè£…æ¸ˆã¿æ˜è¨˜ï¼‰")
        print("   6. âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ»å®Ÿè¡Œæ™‚åˆ‡æ›¿ã‚µãƒ³ãƒ—ãƒ«")
        print("   7. âœ… ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯å¼·åŒ–")
        print("   8. âœ… usage ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—å¯¾å¿œ")
        print("   9. âœ… åŒ…æ‹¬çš„ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°")
        print("   10. âœ… ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³å¯¾å¿œæ©Ÿèƒ½")
        
        print("\nğŸš€ æº–å‚™å®Œäº†æ©Ÿèƒ½:")
        print("   - ChatGPTå®Œå…¨äº’æ›API")
        print("   - çœŸã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œ")
        print("   - è©³ç´°ã‚¨ãƒ©ãƒ¼åˆ†é¡ãƒ»è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤")
        print("   - ãƒ¢ãƒ‡ãƒ«ç™ºè¦‹ãƒ»æ¤œè¨¼æ©Ÿèƒ½")
        print("   - ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç´šã®ä¿¡é ¼æ€§")
        print("   - LangChainæœ€æ–°ç‰ˆå®Œå…¨å¯¾å¿œ")
        
        print("\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("   1. å®Ÿéš›ã®IO Intelligence APIã§ã®å‹•ä½œç¢ºèª")
        print("   2. Git push & PyPI v0.2.0 ãƒªãƒªãƒ¼ã‚¹")
        print("   3. æœ¬ç•ªç’°å¢ƒã§ã®çµ±åˆãƒ†ã‚¹ãƒˆ")
        
    else:
        print(f"\nâš ï¸ {failed}å€‹ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
        print("ä¿®æ­£ãŒå¿…è¦ãªå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
    
    return failed == 0

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
